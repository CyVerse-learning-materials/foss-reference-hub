{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The FOSS Reference Hub","text":"<p>This GitHub page is a reference and companion repository to the FOSS 2023 course.</p>"},{"location":"#objective","title":"Objective","text":"<p>The goal of this page is to provide FOSS learners with an idea of what (hopefully) a well constructed GitHub repository should look like.</p> <p>Throughout FOSS, learners will be given the opportunity to reinforce their knowledge through self-paced assignments: a novel topic will be covered each week, and at the end of the lesson learners will be asked to add their newly gained knowledge to their own GitHub repository. This repository aims to be a reference learners can use when adding to their own work.</p>"},{"location":"#structure","title":"Structure","text":"<p>The repository aims to represent a well structured page for a research tool following FAIR and CARE principles. In addition, the resporitory tries to follow best practices for project management, data management, version control and documentation with the goal of being reproducible for collaborators and potential contributors.</p> <p>Each of the aims discussed above are associated with their specific FOSS lessons:</p> <ul> <li>Managing Data</li> <li>Project Management</li> <li>Documentation and Communication</li> <li>Version Control</li> <li>Reproducibility</li> </ul>"},{"location":"#repository-organization","title":"Repository Organization","text":"<pre><code>.\n\u251c\u2500\u2500 AUTHORS.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 mkdocs.yml                      &lt;- Governing file for website building\n\u251c\u2500\u2500 requirements.txt                &lt;- Requirements file for pip installation (required by website)\n\u251c\u2500\u2500 code\n\u2502   \u251c\u2500\u2500 src\n\u2502   \u2502   \u251c\u2500\u2500 *.py                    &lt;- Python files part of dplPy\n\u2502   \u2502   \u2514\u2500\u2500 execution_sample.ipynb  &lt;- runnable example (executable Jupyter notebook)\n\u2502   \u251c\u2500\u2500 Dockerfile                  &lt;- Docker script in charge of container creation\n\u2502   \u2514\u2500\u2500 tests_data                  &lt;- Data from third party sources used for testing (in rwl and csv formats.\n\u2502       \u251c\u2500\u2500 csv\n\u2502       \u2514\u2500\u2500 rwl        \n\u2514\u2500\u2500 docs                           \n    \u251c\u2500\u2500 assets                      &lt;- Folder for images and additional graphic assets\n    \u251c\u2500\u2500 stylesheets                 &lt;- Folder containing style-related code for the website\n    \u251c\u2500\u2500 index.md                    &lt;- Main website home page\n    \u251c\u2500\u2500 installation.md             &lt;- Installation steps for dplPy\n    \u251c\u2500\u2500 manual.md                   &lt;- Manual for dplPy\n    \u251c\u2500\u2500 Data_Management_Plan.md     &lt;- Data Management Plan (example) applicable for this repository\n    \u2514\u2500\u2500 Governance_Operations.md    &lt;- Governance &amp; Operations (example) file applicable for this repsitory\n</code></pre>"},{"location":"#statements","title":"Statements","text":"<p>This repository  We respectfully acknowledge the University of Arizona is on the land and territories of Indigenous peoples. Today, Arizona is home to 22 federally recognized tribes, with Tucson being home to the O\u2019odham and the Yaqui. Committed to diversity and inclusion, the University strives to build sustainable relationships with sovereign Native Nations and Indigenous communities through education offerings, partnerships, and community service.</p>"},{"location":"Data_Management_Plan/","title":"Data Management Plan","text":"<p>This document takes into consideration data that would be collected and made available for dplPy and dendrochronologist to use.</p>"},{"location":"Data_Management_Plan/#1-data-description","title":"1. Data Description","text":"<p>We will collect tree ring measurements from various tree species in our study area. Data will include tree ring width measurements, corresponding years, and species information. These measurements will be stored in structured CSV and RWL files, with metadata indicating sample location, collection date, and field methods.</p>"},{"location":"Data_Management_Plan/#2-data-collection","title":"2. Data Collection","text":"<p>Tree cores will be extracted from trees using increment borers. Ring width measurements will be taken using specialized equipment. Species identification will be done based on field observations and confirmed through lab analysis.</p>"},{"location":"Data_Management_Plan/#3-data-storage-and-backup","title":"3. Data Storage and Backup","text":"<p>Tree ring data and associated metadata will be stored in a dedicated directory on our secure research server. Automated daily backups will be conducted to ensure data integrity.</p>"},{"location":"Data_Management_Plan/#4-data-organization-and-documentation","title":"4. Data Organization and Documentation","text":"<p>Data will be organized by sample location, species, and collection year. Each dataset will have an accompanying metadata file detailing data structure, variable definitions, and data processing steps. </p> <p>(These metadata files are obtainable when downloading data through the NOAA tree ring archive.)</p>"},{"location":"Data_Management_Plan/#5-data-preservation-and-long-term-access","title":"5. Data Preservation and Long-Term Access","text":"<p>Upon project completion, the dataset will be deposited in a recognized tree ring database or repository, ensuring long-term preservation and discoverability (NOAA). The repository will assign a Digital Object Identifier (DOI) for reliable referencing.</p>"},{"location":"Data_Management_Plan/#6-data-sharing-and-access","title":"6. Data Sharing and Access","text":"<p>After a brief embargo period to allow for primary analysis, the dataset will be openly accessible through the repository under a Creative Commons Attribution (CC-BY) license, promoting data reuse with proper attribution.</p>"},{"location":"Data_Management_Plan/#7-data-ethics-and-legal-compliance","title":"7. Data Ethics and Legal Compliance","text":"<p>Ethics approval has been obtained for the study. All data collection follows ethical guidelines, and any potential impact on tree populations or ecosystems will be minimized.</p>"},{"location":"Data_Management_Plan/#8-roles-and-responsibilities","title":"8. Roles and Responsibilities","text":"<p>The lead dendrochronologist will oversee data management, ensuring accuracy and quality. Field technicians will collect core samples and measurements. The institution's data management team will facilitate repository submission.</p>"},{"location":"Data_Management_Plan/#9-budget-and-resources","title":"9. Budget and Resources","text":"<p>Funding has been allocated for specialized dendrochronology equipment, data storage, repository fees, and data management software.</p> <p>This Data Management Plan ensures responsible collection, storage, and sharing of tree ring data, in adherence to dendrochronological best practices and ethical standards. It promotes the transparency, reproducibility, and accessibility of tree ring research.</p>"},{"location":"Governance_Operations/","title":"dplPy-for-FOSS Governance and Operations Document","text":"<p>This is a living document. Changes are expected throughout the life of the project.</p>"},{"location":"Governance_Operations/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction<ul> <li>Project Overview and Objectives<ul> <li>dplPy</li> <li>FOSS Reference Hub</li> </ul> </li> <li>Our Team<ul> <li>Organizational Structure</li> </ul> </li> </ul> </li> <li>Operations<ul> <li>Communications</li> <li>Procedures</li> </ul> </li> <li>Community Practices<ul> <li>Open Science Commitment</li> <li>Land Acknowledgement</li> <li>Diversity Statement</li> <li>Code of Conduct</li> </ul> </li> <li>Attribution, Authorship, and Ownership</li> </ol>"},{"location":"Governance_Operations/#introduction","title":"Introduction","text":"<p>This Project Governance document defines operating procedures and rules aimed to clarify and support the involvement of dplPy in FOSS and the FOSS reference hub.</p>"},{"location":"Governance_Operations/#project-overview-and-objectives","title":"Project Overview and Objectives","text":"<p>This section highights the dplPy project on its own and its implementation in the FOSS Reference Hub.</p>"},{"location":"Governance_Operations/#dplpy","title":"dplPy","text":"<p>dplPy is the Python implementation of the OpenDendro project, an open-source framework that aims to provide dendrochronologists with the required analytical software necessary for tree-ring related research. The majority of the code for dplPy was developed by Ifeoluwa Ale, a student Computer Scienctist at the University of Arizona, and supervised by Michele Cosi, Dr. Tyson Swetnam, and Dr. Kevin Anchukaitis. OpenDendro is supervised by Dr. Kevin Anchukaitis, Andy Bunn, Dr. Tyson Swetnam and Dr. Edward Cook.</p>"},{"location":"Governance_Operations/#foss-reference-hub","title":"FOSS Reference Hub","text":"<p>The FOSS reference hub is a reference repository for the Foundational Open Science Skills (FOSS) workshop series. Together with dplPy, the aim of this repository is to serve as a reference for the capstone, which FOSS attendees are expected to complete within the duration of the FOSS workshop.</p> <p>The dplPy project was selected to enhance the FOSS Reference Hub with a reliable codebase, ensuring it mirrors a genuine repository that participants can use as a model when attempting to replicate similar setups for their individual projects.</p> <p>The goals of the FOSS Reference Hub are to: - Serve as an exemplary reference for a well structured research object. - Guide FOSS attendees through weekly exercises designed to progressively enhance their project repositories.</p>"},{"location":"Governance_Operations/#our-team","title":"Our Team","text":"<p>Meet the education team at CyVerse/Data Science Institute:</p> <ul> <li>Tyson Swetnam: Co-PI of CyVerse and Director of Open Science, Institute for Computation and Data-enabled Insight (ICDI) at the University of Arizona</li> <li>Jeff Gillan: Data Scientist for CyVerse with relative research in the field of GIS/remote sensing.</li> <li>Carlos Lizarraga: Educator in Computational and Data Science at the University of Arizona Data Science Institute. Carlos' background is in applied research scientist as a Professor from the Physics Department at the University of Sonora, where he taught Computational Physics.</li> <li>Michele Cosi: Science Analyst for CyVerse with a background in genetics and genomics of rice.</li> <li>Tina Lee: Head of User Engagement at CyVerse.</li> </ul> <p>With the collaboration of the dplPy team: </p> <ul> <li>Andy Bunn: Environmental scientist interested in climate and energy from the College of Environment at Western Washington University, founding director of the Institute for Energy Studies, and main writer of OpenDendro software dplR and xDateR. </li> <li>Edward Cook: expert in the dendrochronology field and main writer of the tool ARSTAN. </li> <li>Kevin Anchukaitis: Climate scientist, paleoclimatologist, dendrochronologist, faculty member  in Geosciences and the Laboratory of Tree-Ring Research at the University of Arizona, leading the efforts behind the OpenDendro platform.</li> <li>Ifeuwa Ale: Junior Computer Science student at the University of Arizona and main contributor to the dplPy codebase for OpenDendro.</li> </ul> <p>FOSS will also be hosting the following guest speakers:</p> <ul> <li>Jason Williams: Assistant Director, Diversity and Research Readiness at the  DNA Learning Center of Cold Spring Harbor.</li> <li>Wade Bishop: Professor in the School of Information Sciences at the University of Tennessee-Knoxville. He is the Director of Graduate Studies as well as the Research Data Management Certificate Coordinator</li> </ul>"},{"location":"Governance_Operations/#organizational-structure","title":"Organizational Structure","text":"<pre><code>FOSS\n\u251c\u2500\u2500 CyVerse/Data Science Institute\n\u2502   \u251c\u2500\u2500 Tyson Swetnam \n\u2502   \u251c\u2500\u2500 Jeff Gillan\n\u2502   \u251c\u2500\u2500 Carlos Lizarraga\n\u2502   \u251c\u2500\u2500 Tina Lee\n\u2502   \u2514\u2500\u2500 Michele Cosi\n\u251c\u2500\u2500 FOSS Reference Hub\n\u2502   \u2514\u2500\u2500 dplPy\n\u2502        \u251c\u2500\u2500 Kevin Anchukaitis\n\u2502        \u251c\u2500\u2500 Edward Cook\n\u2502        \u251c\u2500\u2500 Andy Bunn\n\u2502        \u2514\u2500\u2500 Ifeuwa Ale\n\u2514\u2500\u2500 Guest Speakers\n    \u251c\u2500\u2500 Jason Williams\n    \u2514\u2500\u2500 Wade Bishop\n</code></pre>"},{"location":"Governance_Operations/#operations","title":"Operations","text":"<p>In order to ensure well distributed work loads across FOSS and the FOSS teaching materials including the FOSS Reference Hub, we have outlined communications and procedure components in order to maximize effectiveness and efficiency.</p>"},{"location":"Governance_Operations/#communications","title":"Communications","text":"<p>Internal communications: communications within the CyVerse/Data Science Institute team is carried out through private Slack channels (CyVerse, CyVerseLearning, Data7) and Zoom meetings.</p> <p>External communications: communications to the dplPy team is carried out through a private Slack channel (openDendro), whilst communication to the guest speakers is done through email (Wade Bishop) and the CyVerse/CyverseLearning Slack Channel (Jason Williams).</p> <p>Note keeping &amp; attendees: communications to FOSS attendees is achieved through the CyVerseLearning Slack channel. This will allow attendees to share thoughts and notes on lectures and materials during and after the workshop. Note keeping during the workshop is carried out through HackMD, which links are shared during the workshop sessions. All workshops will be done through Zoom, creating a virtual classroom environment allowing remote attendees to take part to the workshop. Recordings of these workshop sessions will be made available to attendees through a private YouTube playlist. </p>"},{"location":"Governance_Operations/#procedures","title":"Procedures","text":"<p>All of the code base required for FOSS, the FOSS Reference Hub and the dplPy project is stored in their respective GitHub repositories:</p> <ul> <li>FOSS</li> <li>FOSS Reference Hub</li> <li>dplPy </li> </ul> <p>All of these repositories can only be modified by the CyVerse/Data Science Institute team (or the dplPy team regarding the dplPy repository) or through a reviewed pull request. Websites for FOSS (foss.cyverse.org) and OpenDendro (opendendro.org) are created using MkDocs-Material and hosted on GitHub Pages, built through automated GitHub Actions.</p>"},{"location":"Governance_Operations/#community-practices","title":"Community Practices","text":""},{"location":"Governance_Operations/#open-science-commitment","title":"Open Science Commitment","text":"<p>We are committed to Open Science as we operate through transparency, collaboration, and accessibility, guided by theFAIR (Findable, Accessible, Interoperable, Reusable) and CARE (Collective Benefit, Accountability, Responsibility, Equity) principles.</p> <p>Our educational materials and publications are thoughtfully curated to align with Open Science ideals. We seek to empower others to adopt and implement Open Science practices, making research more accessible and reproducible.</p>"},{"location":"Governance_Operations/#land-acknowledgement","title":"Land Acknowledgement","text":"<p>As part of the University of Arizona, we acknowledge and respect the land and territories on which we are able to perform our duties as educators with the following statement: We respectfully acknowledge the University of Arizona is on the land and territories of Indigenous peoples. Today, Arizona is home to 22 federally recognized tribes, with Tucson being home to the O\u2019odham and the Yaqui. Committed to diversity and inclusion, the University strives to build sustainable relationships with sovereign Native Nations and Indigenous communities through education offerings, partnerships, and community service.</p>"},{"location":"Governance_Operations/#diversity-statement","title":"Diversity Statement","text":"<p>We encourage everyone to participate and are committed to building a community for all.  Although we will fail attimes, we seek to treat everyone as fairly and equally as possible. Whenever a participant has made a mistake, we expect them to take responsibility for it. If someone has been harmed or offended, if you are a witness to an event of this nature, it is your responsibility to both listen carefully and respectfully to the victims, as well as to take action to bring attention to the behaviour, and to make every effort to stop the behaviour. </p> <p>It is also our responsibility to do our best to right the wrong.  Although this list cannot be exhaustive, we explicitly honor diversity in age, gender, gender identity or expression, culture, ethnicity, language, national origin, political beliefs, profession, race, religion, sexual orientation, socioeconomic status, and technical ability. We will not tolerate discrimination based on any of the protected characteristics above, including participants with disabilities.</p>"},{"location":"Governance_Operations/#code-of-conduct","title":"Code of Conduct","text":"<p>In conjunction with for using CyVerse cyberinfrastructure, this Code of Conduct applies to all Event participants and their activities while using CyVerse resources and/or attending the Event.</p> <p>CyVerse is dedicated to providing professional computational research and educational experiences for all of our users, regardless of domain focus, academic status, educational level, gender/gender identity/expression, age, sexual orientation, mental or physical ability, physical appearance, body size, race, ethnicity, religion (or lack thereof), technology choices, dietary preferences, or any other personal characteristic.</p> <p>When using CyVerse or participating at an Event, we expect you to:</p> <p>Interact with others and use CyVerse professionally and ethically by complying with our Policies. Constructively critize ideas and processes, not people. Follow the Golden Rule (treat others as you want to be treated) when interacting online or in-person with collaborators, trainers, and support staff. Comply with this Code in spirit as much as the letter, as it is neither exhaustive nor complete in identifying any and all possible unacceptable conduct. We do not tolerate harassment of other users or staff in any form (including, but not limited to, violent threats or language, derogatory language or jokes, doxing, insults, advocating for or encouraging any of these behaviors). Sexual language and imagery are not appropriate at any time (excludes Protected Health Information in compliance with HIPAA). Any user violating this Code may be expelled from the platform and the workshop at CyVerse's sole discretion without warning.</p> <p>To report a violation of this Code, directly message a trainer via Slack or email info@cyverse.org with the following information:</p> <p>Your contact information Names (real, username, pseudonyms) of any individuals involved, and or witness(es) if any. Your account of what occurred and if the incident is ongoing. If there is a publicly available record (a tweet, public chat log, etc.), please include a link or attachment. Any additional information that may be helpful in resolving the issue.</p>"},{"location":"Governance_Operations/#attribution-authorship-and-ownership","title":"Attribution, Authorship, and Ownership","text":"<p>FOSS teaching materials and FOSS Reference Hub are made available under the CC BY 4.0 License: https://creativecommons.org/licenses/by/4.0/legalcode.</p> <p>dplPy and OpenDendro are made available under the GNU General Public Licence v3.0: https://creativecommons.org/licenses/by/4.0/legalcode</p> <p>We kindly ask to respect the Licences by which this material is developed.</p>"},{"location":"installation/","title":"The dplPy Codebase","text":"<p>Welcome to dplPy. </p>"},{"location":"installation/#requirements-installation-and-accessibility","title":"Requirements, Installation and Accessibility","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Git </li> <li>Python v3.10=&lt; (although functional on Python v3.8=&lt;, we suggest using Python v3.10=&lt;)</li> <li>Pip</li> <li>Miniconda3 (suggestion: select the python 3.10 version that best fits your OS)</li> </ul> <p>Suggested:</p> <ul> <li>VSCode</li> <li>Mamba: repository, anaconda.org link</li> </ul>"},{"location":"installation/#installation","title":"Installation","text":"<p>Future plans</p> <p>dplPy is planned to be released as a <code>pip</code> and <code>conda</code> packages for easy installation (e.g., <code>pip install dplpy</code> or <code>conda install -c conda-forge dplpy</code>). However, the current installation process for dplPy requires manual steps to be performed after cloning the GitHub repository.</p> <ol> <li>Clone this repository to your personal machine: <code>git clone https://github.com/OpenDendro/dplPy.git</code>; move into the repository <code>cd code/</code></li> <li>Build conda environment: <code>conda env create -f environment.yml</code> or <code>mamba env create -f environment.yml</code> if Mamba is installed; Activate environment: <code>conda activate dplpy</code></li> </ol> <p>Known Issues</p> <p>The CSAPS package, required for smoothing splines, may fail to install in rare occasions. If that is the case, please install CSAPS manually by doing <code>pip install -U csaps</code>.</p>"},{"location":"installation/#accessing-dplpy-via-jupyter-notebook","title":"Accessing dplPy via Jupyter Notebook","text":"<p>Although dplPy is executable from the command line interface (CLI), e.g., BASH, ZSH, or a Cygwin terminal, the usage of Jupyter Notebooks is suggested for visualizing graphs.</p> <p>Making the dplPy kernel findable</p> <p>It is possible that your computer will not automatically find the dplPy [kernel](https://en.wikipedia.org/wiki/Kernel_(operating_system). If that is the case, execute the following command:</p> <pre><code>python -m ipykernel install --user --name dplpy --display-name \"Python (dplpy)\"\n</code></pre> <p>This will ensure that the dplPy environment created through conda is findable by Jupyter under the name <code>Python (dplpy)</code>.</p> <p>The dplPy Git repository contains:</p> <pre><code>- source code (`src/`)\n- A jupyter notebook example (`runnable_example.ipynb`)\n- Test files in `csv` and `rwl` formats (`tests/data/&lt;format&gt;/`)\n</code></pre>"},{"location":"installation/#accessing-jupyter-notebook-on-linux-macos","title":"Accessing Jupyter Notebook on Linux, MacOS","text":"<ol> <li>In your VScode terminal, activate the conda environment with <code>conda activate dplpy</code>.</li> <li>From the terminal, execute <code>jupyter notebook</code>.</li> <li>If prompted to select a kernel, select <code>dplpy</code>. This will automatically load the correct environment.</li> </ol>"},{"location":"installation/#accessing-jupyter-notebook-on-windows","title":"Accessing Jupyter Notebook on Windows","text":"<p>In VScode:</p> <ol> <li>In your VSCode terminal window, activate the conda environment with <code>conda activate dplpy</code>. </li> <li>In the same terminal window, start a Jupyter Notebook with <code>jupyter notebook</code>. Jupyter will then return URLs that you can copy; Copy one of these URLs.</li> <li>When propted to select a kernel (top right), select Select Another Kernel &gt; Existing Jupyter Server and paste the URL you have copied.</li> <li>Jupyter Notebook will now be able to access the environment created.</li> </ol>"},{"location":"installation/#import-the-dplpy-library","title":"Import the <code>dplpy</code> library","text":"<p>dplPy currently exists as a python library; ensure you are in the correct folder prior to execution. In a Jupyter Notebook, execute the following lines:</p> <pre><code>import os\ndirectory = os.getcwd().split(\"/\")\nif directory[-1] != 'src':\n    os.chdir(\"./src\")\nimport dplpy as dpl\n</code></pre> <p>Currently, the dplPy codebase is executable from within the <code>src</code> folder. There, you will find <code>execution_sample.ipynb</code>, which is an example file where you can execute dplPy.</p>"},{"location":"installation/#user-manual","title":"User Manual","text":"<p>See the dplPy User Manual</p>"},{"location":"manual/","title":"The dplPy User Manual (Beta)","text":"<p>Welcome to the dplPy manual.</p>"},{"location":"manual/#usage","title":"Usage","text":"<p>DplPy is currently available as a Python module with a number of functions, which in turn have parameters one can set. Here is a list of functions for dplPy (in alphabetical order):</p> Function Description <code>ar_func</code> Fits series to autoregressive (AR) models and related functions <code>autoreg</code> Fits series to autoregressive (AR) models and related functions <code>chron</code> Creates a mean value chronology for a dataset, typically the ring width indices of a detrended series <code>detrend</code> Detrends a given series or data frame, first by fitting data to curve(s), with spline(s) as the default, and then by calculating residuals or differences compared to the original data. <code>help</code> Displays help (alpha). <code>plot</code> Generates line, spaghetti or segment plots. <code>rbar</code> Finds best interval of overlapping series over a  period of years, and calculating rbar constant for a dataset over period of overlap. <code>readers</code> Reads data from supported file types (*.CSV and *.RWL) and stores them in dataframe. <code>readme</code> Goes to this website. <code>report</code> Generates a report about absent rings in the data set. <code>series_corr</code> Crossdating function that focuses on the comparison of one series to the master chronology. <code>stats</code> Generates summary statistics for RWL and CSV format files. <code>summary</code> Generates a summary for RWL and CSV format files. <code>xdate</code> Crossdating function for dplPy loaded datasets."},{"location":"manual/#ar_func","title":"<code>ar_func</code>","text":"<p>Main function for autoregressive (AR) modeling. Returns residuals and mean of best AR fit with specified lag (default = 5).</p> <p>Usage</p> <pre><code>&gt;&gt;&gt; dpl.ar_func(&lt;data&gt;[\"&lt;series&gt;\"], &lt;lag number&gt;)\n</code></pre> <p>Example: <pre><code>&gt;&gt;&gt; dpl.ar_func(ca533[\"CAM191\"], 10) \n</code></pre></p> <p>In the above example, we use dataset look at dataset <code>ca533</code> series <code>CAM191</code>  and specified a lag of <code>10</code>.</p> <p>Expected output(s)</p> <p>Users can expect an array of residual+mean for selected series. </p> <p>The expected output from the example above will look similar to this: <pre><code>array([ 0.71130658, -0.23204695,  0.52121028,  0.57597523,  0.90108448,\n        0.20495808, -0.23457629,  0.58819405,  0.66478718,  0.47521983,\n        0.92695177, -0.35659493,  0.42220031, -0.19197698, -0.08828572,\n        0.5320343 ,  0.28471761,  0.39486259,  0.10748019,  0.25214937,\n        0.46500727,  1.45016901,  0.28605889,  0.29470389,  0.34120629,\n       -0.31249819,  0.42380461,  0.23473108, -0.06796468,  0.38897624,\n        0.68666198,  0.77677716,  0.62360082,  0.43398575,  0.74032758,\n        0.5880663 ,  0.20567916,  0.23525549,  0.63297387,  0.94101874,\n        0.06615244,  0.73838454,  0.51092414,  0.25087689,  0.3873105 ,\n        0.48383716,  0.28317419,  0.46750972,  0.60187677,  0.40542752,\n        0.54822178,  0.08560112,  0.26122762,  0.13318504,  0.25876284,\n        0.56315817,  0.40823334,  0.36114307,  0.49613157,  0.4169329 ,\n        0.40733772,  0.25578201,  0.42718681,  0.59555259, -0.21075308,\n        0.11587297,  0.62082607,  0.65467697, -0.17674732,  0.56107325,\n        0.51825623,  0.58111792,  0.61318262,  0.3742455 ,  0.07211766,\n        0.01136486,  0.06596661,  0.32254786,  0.39898574,  0.22616678,\n        0.34727753,  0.42409955,  0.51594014,  0.23294973,  0.50911683,\n        0.84802911,  0.48218982,  0.393356  ,  0.22153173,  0.65209051,\n        0.48231136,  0.19053267,  0.39660363,  0.39800466,  0.29138228,\n       -0.030384  ,  0.49157549,  0.49579055,  0.25640508,  0.48196172,\n        0.28278419,  0.53502938,  0.41559126,  0.34577752,  0.33023954,\n        0.55383387,  0.4391052 ,  0.35063736,  0.20157626,  0.25298519,\n        0.51312838,  0.53184596,  0.43997298,  0.27903576,  0.43143646,\n        0.45186539,  0.3734363 ,  0.41050279,  0.67168476,  0.31693981,\n        0.32281309,  0.5155617 ,  0.51985799,  0.48651392,  0.50650445,\n...\n        0.39541278,  0.47066705,  0.34558178,  0.46008747,  0.34158785,\n        0.3672973 ,  0.37749446,  0.34939726,  0.37388067,  0.4241256 ,\n        0.23815543,  0.29207569,  0.47247813,  0.44170539,  0.4410876 ,\n        0.4007522 ,  0.29655365,  0.38460918,  0.39774193,  0.42761775,\n        0.38384653])\n</code></pre></p>"},{"location":"manual/#autoreg","title":"<code>autoreg</code>","text":"<p>Secondary function for AR modeling. Returns parameters of best fit AR model with specified lag (default = 5); Best AR model is selected based on AIC value.</p> <p>Note</p> <p>This function and its outputs are integrated in the <code>ar_func</code> function.</p> <p>Usage</p> <pre><code>&gt;&gt;&gt; dpl.autoreg(&lt;data&gt;[\"&lt;series&gt;\"], &lt;lag number&gt;)\n</code></pre> <p>Example: <pre><code>dpl.autoreg(ca533[\"CAM191\"], 10)\n</code></pre></p> <p>Expected output(s)</p> <p>A table listing autoregressive paramenters for the specified series;</p> <p>The expected output from the example above will look similar to this: <pre><code>const         0.022210\nCAM191.L1     0.503373\nCAM191.L2     0.087230\nCAM191.L3     0.143716\nCAM191.L4     0.020119\nCAM191.L5    -0.027769\nCAM191.L6    -0.010029\nCAM191.L7     0.001373\nCAM191.L8     0.025588\nCAM191.L9     0.042340\nCAM191.L10    0.136916\ndtype: float64\n</code></pre></p>"},{"location":"manual/#chron","title":"<code>chron</code>","text":"<p>Creates a mean value chronology for a dataset, typically the ring width indices of a detrended series. Takes three optional arguments <code>biweight</code>, <code>prewhiten</code>, and <code>plot</code>. They determine whether to find means using tukey's biweight robust mean (default True), whether to prewhiten data by fitting to an AR model (default False), and whether to plot the results of the chronology (default True).</p> <p>Usage</p> <pre><code>&gt;&gt;&gt; dpl.chron(&lt;data&gt;, prewhiten=&lt;True/False&gt;, biweight=&lt;True/False&gt;, plot=&lt;True/False&gt;)\n</code></pre> <p>Example: <pre><code># Detrending data first\n&gt;&gt;&gt; rwi_data = dpl.detrend(ca533)\n\n# Creating chronology using detrended data \n&gt;&gt;&gt; dpl.chron(rwi_ca533, prewhiten=False, biweight=True, plot=True)\n</code></pre></p> <p>Expected output(s)</p> <p>The expected output is the mean value chronology of a specific dataframe.</p> <p>The expected output from the example above will look similar to this: <pre><code>        Mean RWI    Sample depth\nYear        \n626     0.371605    1\n627     0.284398    1\n628     0.306523    1\n629     0.416333    1\n630     0.482462    1\n...     ...         ...\n1979    1.053427    21\n1980    1.455353    21\n1981    1.252526    21\n1982    1.362244    21\n1983    1.314827    21\n1358 rows \u00d7 2 columns\n</code></pre></p> <p>If <code>plot=True</code> then a plot will also be generated:</p> <p></p>"},{"location":"manual/#detrend","title":"<code>detrend</code>","text":"<p>Detrends a given series or dataframe, first by fitting data to curve(s), with <code>spline</code> as the default, and then by calculating residuals (default = <code>residual</code>) or differences (<code>difference</code>) compared to the original data. Other supported curve fitting methods are <code>ModNegex</code> (modified negative exponential), <code>Hugershoff</code>, <code>linear</code>, <code>horizontal</code>.</p> <p>Usage</p> <pre><code># Detrend the entire dataframe\n&gt;&gt;&gt; dpl.detrend(&lt;data&gt;)\n\n# Detrending a series part of the dataframe\n&gt;&gt;&gt; dpl.detrend(&lt;data&gt;[\"&lt;series&gt;\"])\n\n# Detrending function and its options\n&gt;&gt;&gt; dpl.detrend(&lt;data&gt;[\"&lt;series&gt;\"], fit=\"&lt;fitting method&gt;\", method=\"&lt;comparison method&gt;\", plot=&lt;True/False&gt;) \n</code></pre> <p>Example: <pre><code># Detrending series CAM191 from dataframe ca533, using the spline fitting method and calculating residuals compared to the original data \n&gt;&gt;&gt; rwi_data = dpl.detrend(ca533[\"CAM191\"], fit=\"spline\", method=\"residual\", plot=True)\n\n# Creating chronology using detrended data \n&gt;&gt;&gt; dpl.chron(rwi_ca533, prewhiten=False, biweight=True, plot=True)\n</code></pre></p> <p>Expected output(s)</p> <p>The expected output is the a list of detrended values (for the entire dataset or for a specific series)</p> <p>The expected output from the example above will look similar to this: <pre><code>1180    1.180835\n1181    1.511543\n1182    1.870558\n1183    2.197630\n1184    1.815025\n        ...   \n1966    1.060515\n1967    1.209514\n1968    1.282459\n1969    1.392746\n1970    1.239629\nName: CAM191, Length: 791, dtype: float64\n</code></pre></p> <p>If <code>plot=True</code> then a plot will also be generated:</p> <p></p>"},{"location":"manual/#help","title":"<code>help</code>","text":"<p>Under Development</p> <p>Usage</p> <pre><code>&gt;&gt;&gt; dpl.help()\n</code></pre>"},{"location":"manual/#plot","title":"<code>plot</code>","text":"<p>Plots a given dataframe or series of a specific dataframe in either line (default), spaghetti (<code>spag</code>) or segment (<code>seg</code>) plots.</p> <p>Usage</p> <pre><code># Plot entire data\n&gt;&gt;&gt; dpl.plot(&lt;data&gt;)\n\n# Plot series subset of dataframe with a specified plot type\n&gt;&gt;&gt; dpl.plot(&lt;data&gt;[\"&lt;series&gt;\"], type=&lt;plot type&gt;)\n</code></pre> <p>Example: <pre><code># Plotting entire dataset with a spaghetti plot\n&gt;&gt;&gt; dpl.plot(ca533, type=spag)\n</code></pre></p> <p>Expected output</p> <p>A graph of the specified dataframe.</p> <p>From the example above, the expected output would look something similar to the below plot:</p> <p></p>"},{"location":"manual/#rbar","title":"<code>rbar</code>","text":"<p>Finds best interval of overlapping series over a long period of years and calculates rbar constant for a dataset. Supports a number of rbar methods: <code>osborn</code>, <code>67spline</code>, <code>frank</code>.</p> <p>Further development underway. Future versions to prioritize number of series, number of years or both. Current version attempts to do both.</p> <p>Usage</p> <pre><code># Detrend data\n&gt;&gt;&gt; rwi_data = dpl.detrend(&lt;data&gt;, plot=False)\n\n# Find common interval of detrended data\n&gt;&gt;&gt; start, end = dpl.common_interval(&lt;data&gt;)\n\n# Calculate rbar coonstant\n&gt;&gt;&gt; dpl.rbar(rwi_data, start, end, method=\"&lt;rbar method&gt;\")\n</code></pre> <p>Example: <pre><code># Detrend data\n&gt;&gt;&gt; rwi_data = dpl.detrend(ca533, plot=False)\n\n# Find common interval of detrended data\n&gt;&gt;&gt; start, end = dpl.common_interval(ca533)\n\n# Calculate rbar coonstant using the interval calculated above and using the Osborn method\n&gt;&gt;&gt; dpl.rbar(rwi_data, start, end, method=\"osborn\")\n</code></pre></p> <p>Expected output</p> <p>rbar returns a list of constants to multiply with each mean value generated for a range of years from a mean value chronology.</p> <p>From the example above, the output is the following: <pre><code>[0.44170725878965766,\n0.44170725878965766,\n0.44170725878965766,\n0.44170725878965766,\n0.44170725878965766,\n0.44170725878965766,\n...\n0.44170725878965766,\n0.44170725878965766,\n0.44170725878965766,\n0.44170725878965766,\n0.44170725878965766]\n</code></pre></p>"},{"location":"manual/#readers","title":"<code>readers</code>","text":"<p>Reads data and stores them in a dataframe.</p> <p>Supported data types</p> <pre><code>dplPy currently supports `csv` and `rwl` data formats.\n</code></pre> <p>Usage</p> <pre><code>&gt;&gt;&gt; data = dpl.readers(\"&lt;path/to/data.format&gt;\")\n</code></pre> <p>Example:</p> <pre><code>&gt;&gt;&gt; data  = dpl.readers(\"ca533.rwl\")\n</code></pre> <p>Expected output</p> <ul> <li>A success/failure message;</li> <li>A list of series within the data file such as the following:</li> </ul> <pre><code>Attempting to read input file: ca533.rwl as .rwl format\n\nSUCCESS!\nFile read as: .rwl file\n\nSeries names:\n['CAM011', 'CAM021', 'CAM031', 'CAM032', 'CAM041', 'CAM042', 'CAM051', 'CAM061', 'CAM062', 'CAM071', 'CAM072', 'CAM081', 'CAM082', 'CAM091', 'CAM092', 'CAM101', 'CAM102', 'CAM111', 'CAM112', 'CAM121', 'CAM122', 'CAM131', 'CAM132', 'CAM141', 'CAM151', 'CAM152', 'CAM161', 'CAM162', 'CAM171', 'CAM172', 'CAM181', 'CAM191', 'CAM201', 'CAM211'] \n</code></pre>"},{"location":"manual/#readme","title":"<code>readme</code>","text":"<p>The readme function opens the opendendro webpage.</p> <p>Usage</p> <pre><code>&gt;&gt;&gt; dpl.readme()\n</code></pre>"},{"location":"manual/#report","title":"<code>report</code>","text":"<p>Generates a report about the input dataset that includes:</p> <ul> <li>Number of dated series</li> <li>Number of measurements</li> <li>Avg series length</li> <li>Range</li> <li>Span</li> <li>Mean (Std dev) series intercorrelation</li> <li>Mean (Std dev) AR1</li> <li>Years with absent rings listed by series</li> </ul> <p>Usage</p> <pre><code>&gt;&gt;&gt; dpl.report(&lt;data&gt;)\n</code></pre> <p>Example: <pre><code>&gt;&gt;&gt; dpl.report(ca533)\n</code></pre></p> <p>Expected output</p> <p>From the example above, the expected output is the following:</p> <pre><code>Number of dated series: 34\nNumber of measurements: 23276\nAvg series length: 684.5882\nRange: 1358\nSpan: 626 - 1983\nMean (Std dev) series intercorrelation:\nMean (Std dev) AR1: 0.7122\n-------------\nYears with absent rings listed by series\n\n    CAM011 -- 1753 1782\n    CAM031 -- 1497 1500 1523 1533 1540 1542 1545 1578 1579 1580 1655 1668 1670 1681\n    CAM032 -- 1497 1523 1579 1654 1670 1681 1782\n    CAM051 -- 1475\n    CAM061 -- 1497 1523 1542 1545 1547 1579 1654 1655 1668 1670 1672 1782 1858 1960\n    CAM062 -- 1542 1545 1547 1548 1579 1654 1655 1670 1672 1782 1836 1857 1858 1929\n    CAM071 -- 1269 1497 1498 1523 1542 1547 1578 1579 1612 1655 1656 1668 1670 1672 1674 1690 1707 1708 1756 1782 1795 1820 1836 1845 1857 1858 1924 1948 1960\n    CAM072 -- 1218 1497 1498 1523 1533 1538 1542 1545 1546 1547 1571 1579 1580 1590 1654 1655 1668 1670 1672 1675 1690\n    CAM081 -- 1218 1336\n    CAM082 -- 1362 1858 1865\n    CAM091 -- 1655 1669 1670 1782 1858\n    CAM092 -- 1624 1654 1655 1670 1672 1675 1677 1690 1703 1705 1707 1708 1710 1733 1753 1756 1757 1774 1777 1781 1782 1783 1784 1795 1807 1824 1829 1836 1845 1857 1858 1899 1904 1929 1936 1961\n    CAM101 -- 1782 1783 1899 1929\n    CAM102 -- 1669 1690 1782 1858 1899 1929\n    CAM111 -- 1542\n...\n    CAM201 -- 1523\n    CAM211 -- 645 762 809 847 924 957 1014 1118 1123 1133 1147 1189 1350 1384 1468 1571 1641\n-------------\n</code></pre>"},{"location":"manual/#series_corr","title":"<code>series_corr</code>","text":"<p>Crossdating function that focuses on the comparison of one series to the master chronology.</p> <p>Usage</p> <pre><code>&gt;&gt;&gt; dpl.series_corr(&lt;data&gt;, \"&lt;series name&gt;\", prewhiten=&lt;True/False&gt;, corr=\"&lt;Pearson/Spearman&gt;\", seg_length=&lt;length of segments (default=50)&gt;, bin_floor=&lt;bin size (default=100)&gt;, p_val=&lt;p value (default=0.05)&gt;, plot=&lt;True/False (default=True)&gt; )\n</code></pre> <p>Example: <pre><code>&gt;&gt;&gt; dpl.series_corr(ca533, \"CAM191\", prewhiten=False, corr=\"Pearson\", bin_floor=10)\n</code></pre></p> <p>Expected output</p> <p>Two graphs: the first graph showing the correlation of one series to against the master chronology in a line graph; the second graph supports the first, showing the correlation in segments. For the example above, the graphs are as following:</p> <p> </p>"},{"location":"manual/#stats","title":"<code>stats</code>","text":"<p>Generates summary statistics for <code>rwl</code>  and <code>csv</code> format files. It outputs a table with <code>first</code>, <code>last</code>, <code>year</code>, <code>mean</code>, <code>median</code>, <code>stdev</code>, <code>skew</code>, <code>gini</code>, <code>ar1</code> for each series in data file.</p> <p>Usage</p> <pre><code>&gt;&gt;&gt; dpl.stats(&lt;data&gt;)\n</code></pre> <p>Example: <pre><code>&gt;&gt;&gt; dpl.stats(ca533)\n</code></pre></p> <p>Expected output</p> <p>Table with <code>first</code>, <code>last</code>, <code>year</code>, <code>mean</code>, <code>median</code>, <code>stdev</code>, <code>skew</code>, <code>gini</code>, <code>ar1</code> for each series in data file. For the example above, the output table is the following:</p> <pre><code>    series  first   last    year    mean    median  stdev   skew    gini    ar1\n1   CAM011  1530    1983    454     0.440   0.40    0.222   1.029   0.273   0.698\n2   CAM021  1433    1983    551     0.424   0.40    0.185   0.946   0.237   0.702\n3   CAM031  1356    1983    628     0.349   0.29    0.214   0.690   0.341   0.809\n4   CAM032  1435    1983    549     0.293   0.26    0.163   0.717   0.309   0.665\n5   CAM041  1683    1983    301     0.526   0.53    0.223   0.488   0.238   0.710\n6   CAM042  1538    1983    446     0.439   0.36    0.348   3.678   0.324   0.881\n7   CAM051  1247    1983    737     0.273   0.25    0.140   1.836   0.262   0.705\n8   CAM061  1357    1983    627     0.462   0.47    0.202   -0.111  0.247   0.510\n9   CAM062  1525    1983    459     0.442   0.45    0.188   -0.266  0.240   0.529\n10  CAM071  1037    1983    947     0.249   0.25    0.109   0.027   0.247   0.578\n11  CAM072  1114    1983    870     0.309   0.29    0.163   0.698   0.292   0.735\n12  CAM081  1081    1983    903     0.327   0.31    0.124   0.555   0.211   0.723\n13  CAM082  977     1983    1007    0.285   0.29    0.114   0.312   0.223   0.771\n14  CAM091  1460    1983    524     0.532   0.52    0.255   0.425   0.267   0.632\n15  CAM092  1591    1983    393     0.349   0.34    0.226   0.337   0.369   0.561\n16  CAM101  1727    1983    257     0.568   0.56    0.260   0.254   0.259   0.716\n17  CAM102  1665    1983    319     0.604   0.62    0.261   0.082   0.243   0.677\n18  CAM111  1446    1983    538     0.625   0.62    0.249   0.196   0.225   0.625\n19  CAM112  1471    1983    513     0.570   0.56    0.211   0.223   0.207   0.583\n20  CAM121  1000    1983    984     0.259   0.26    0.106   0.042   0.231   0.594\n21  CAM122  1000    1983    984     0.271   0.27    0.109   0.346   0.223   0.653\n22  CAM131  695     1970    1276    0.552   0.53    0.198   0.330   0.202   0.788\n23  CAM132  710     1232    523     0.397   0.38    0.148   0.871   0.203   0.810\n24  CAM141  1030    1970    941     0.627   0.60    0.204   0.695   0.177   0.746\n25  CAM151  1222    1970    749     0.446   0.39    0.273   1.068   0.332   0.765\n26  CAM152  1221    1449    229     0.534   0.52    0.195   0.297   0.203   0.695\n27  CAM161  1106    1609    504     0.339   0.33    0.149   0.633   0.243   0.794\n28  CAM162  971     1970    1000    0.397   0.37    0.184   0.647   0.259   0.840\n29  CAM171  1213    1970    758     0.450   0.40    0.210   1.250   0.250   0.799\n30  CAM172  1174    1970    797     0.482   0.42    0.249   1.622   0.268   0.847\n31  CAM181  1190    1970    781     0.283   0.25    0.149   0.706   0.293   0.805\n32  CAM191  1180    1970    791     0.366   0.25    0.336   2.359   0.429   0.876\n33  CAM201  990     1582    593     0.474   0.47    0.181   0.772   0.208   0.709\n34  CAM211  626     1968    1343    0.357   0.34    0.182   0.513   0.286   0.683\n</code></pre>"},{"location":"manual/#summary","title":"<code>summary</code>","text":"<p>The summary function generates a summary of each series recorded in <code>rwl</code>  and <code>csv</code> format files. It outputs a table with <code>count</code>, <code>mean</code>, <code>std</code>, <code>min</code>, <code>25%</code>, <code>50%</code>, <code>75%</code>, <code>max</code> for each series in data file.</p> <p>Usage</p> <pre><code>&gt;&gt;&gt; dpl.summary(&lt;data&gt;)\n</code></pre> <p>Example: <pre><code>dpl.summary(ca533)\n</code></pre></p> <p>Expected output</p> <p>Summary outputs a table with <code>count</code>, <code>mean</code>, <code>std</code>, <code>min</code>, <code>25%</code>, <code>50%</code>, <code>75%</code>, <code>max</code> for each series in data file. For the example above, the output table is the following: <pre><code>        CAM011      CAM021      CAM031      CAM032      CAM041      CAM042      CAM051      CAM061      CAM062      CAM071      ... CAM151      CAM152      CAM161      CAM162      CAM171      CAM172      CAM181      CAM191      CAM201      CAM211\ncount   454.000000  551.000000  628.000000  549.000000  301.000000  446.000000  737.000000  627.000000  459.000000  947.000000  ... 749.000000  229.000000  504.000000  1000.000000 758.000000  797.000000  781.000000  791.000000  593.000000  1343.000000\nmean    0.439581    0.424465    0.349156    0.293224    0.525648    0.439148    0.273012    0.462281    0.441939    0.249071    ... 0.445648    0.533799    0.339464    0.396710    0.450264    0.482296    0.282638    0.366271    0.473929    0.356813\nstd     0.221801    0.185397    0.213666    0.162930    0.222568    0.347705    0.139691    0.201785    0.188389    0.109357    ... 0.272561    0.194947    0.148916    0.184057    0.209848    0.249002    0.148853    0.335788    0.180967    0.182086\nmin     0.000000    0.050000    0.000000    0.000000    0.100000    0.070000    0.000000    0.000000    0.000000    0.000000    ... 0.000000    0.060000    0.000000    0.000000    0.080000    0.080000    0.000000    0.000000    0.000000    0.000000\n25%     0.290000    0.290000    0.180000    0.180000    0.350000    0.270000    0.180000    0.335000    0.330000    0.180000    ... 0.240000    0.410000    0.230000    0.260000    0.300000    0.310000    0.170000    0.170000    0.350000    0.220000\n50%     0.400000    0.400000    0.290000    0.260000    0.530000    0.360000    0.250000    0.470000    0.450000    0.250000    ... 0.390000    0.520000    0.330000    0.370000    0.400000    0.420000    0.250000    0.250000    0.470000    0.340000\n75%     0.540000    0.520000    0.510000    0.390000    0.680000    0.460000    0.330000    0.600000    0.580000    0.320000    ... 0.610000    0.660000    0.430000    0.510000    0.580000    0.590000    0.380000    0.455000    0.580000    0.470000\nmax     1.360000    1.110000    1.030000    0.850000    1.380000    3.030000    1.320000    1.090000    0.920000    0.620000    ... 1.640000    1.250000    0.900000    1.040000    1.540000    1.980000    0.800000    2.540000    1.490000    1.100000\n</code></pre></p>"},{"location":"manual/#xdate","title":"<code>xdate</code>","text":"<p>Crossdating function for dplPy datasets. </p> <p>Usage</p> <pre><code>dpl.xdate(&lt;detrended data&gt;, prewhiten=&lt;True/False&gt;, corr=\"&lt;Pearson/Spearman&gt;\", slide_period=&lt;slide period window (default=50)&gt;, bin_floor=&lt;bin size (default=100)&gt;, p_val=&lt;p value (default=0.05)&gt;, show_flags=&lt;True/False (default=True)&gt;)\n</code></pre> <p>Example: <pre><code># Detrend data first\nca533_rwi = dpl.detrend(ca533, fit=\"spline\", method=\"residual\", plot=False)\n\n# Crossdating of detrended data\ndpl.xdate(ca533_rwi, prewhiten=True, corr=\"Spearman\", slide_period=50, bin_floor=100, p_val=0.05, show_flags=True)\n</code></pre></p> <p>Expected outputs</p> <p>Outputs a dataframe of each series' segment correlations compared to the same segments in the master chronology.</p> <p>For the above example, the expect output dataframe is the following: <pre><code>Flags for CAM011\n[B] Segment  High   -10    -9    -8    -7    -6    -5    -4    -3    -2    -1     0    +1    +2    +3    +4    +5    +6    +7    +8    +9   +10\n1900-1949    6 -0.03 -0.31  0.17 -0.17  0.03 -0.18 -0.15  0.09 -0.16  0.20  0.15 -0.08 -0.03  0.08  0.13 -0.06  0.30  0.20 -0.17  0.09 -0.04\n\nFlags for CAM051\n[B] Segment  High   -10    -9    -8    -7    -6    -5    -4    -3    -2    -1     0    +1    +2    +3    +4    +5    +6    +7    +8    +9   +10\n1375-1424    9 -0.02 -0.21  0.29  0.10 -0.09  0.06  0.30  0.09 -0.01 -0.03  0.18 -0.03 -0.16  0.24 -0.05 -0.06 -0.03  0.03 -0.11  0.38 -0.11\n\nFlags for CAM131\n[A] Segment  High   -10    -9    -8    -7    -6    -5    -4    -3    -2    -1     0    +1    +2    +3    +4    +5    +6    +7    +8    +9   +10\n1800-1849    0 -0.13 -0.13 -0.05  0.05  0.09 -0.03 -0.14 -0.16 -0.00 -0.25  0.13 -0.11  0.10 -0.15  0.01 -0.34  0.09 -0.01  0.09 -0.09  0.05\n\nFlags for CAM171\n[B] Segment  High   -10    -9    -8    -7    -6    -5    -4    -3    -2    -1     0    +1    +2    +3    +4    +5    +6    +7    +8    +9   +10\n1275-1324   -4 -0.04  0.00 -0.11  0.01 -0.05 -0.05  0.46  0.27 -0.13  0.02  0.28  0.23  0.01  0.20  0.12 -0.04  0.03 -0.14  0.01  0.01 -0.13\n\nFlags for CAM181\n[B] Segment  High   -10    -9    -8    -7    -6    -5    -4    -3    -2    -1     0    +1    +2    +3    +4    +5    +6    +7    +8    +9   +10\n1775-1824    8 -0.13  0.05  0.07 -0.06 -0.12  0.19  0.14 -0.36 -0.30  0.06  0.21 -0.02 -0.15  0.16  0.14 -0.05 -0.02 -0.01  0.31  0.05 -0.14\n\nFlags for CAM201\n[A] Segment  High   -10    -9    -8    -7    -6    -5    -4    -3    -2    -1     0    +1    +2    +3    +4    +5    +6    +7    +8    +9   +10\n1350-1399   -7 -0.04  0.03 -0.05  0.25 -0.08 -0.09 -0.13  0.01 -0.08  0.22  0.19  0.17 -0.13  0.13  0.09 -0.14 -0.26  0.03 -0.15 -0.14  0.12\n[B] Segment  High   -10    -9    -8    -7    -6    -5    -4    -3    -2    -1     0    +1    +2    +3    +4    +5    +6    +7    +8    +9   +10\n1125-1174    1 -0.02 -0.03 -0.12 -0.17 -0.08  0.08  0.18  0.00  0.19 -0.27  0.28  0.39  0.12 -0.24  0.01 -0.06 -0.15 -0.00 -0.10 -0.14 -0.18\n...\n1000-1049   -1  0.04  0.07 -0.16 -0.06  0.09 -0.07 -0.24 -0.12 -0.04  0.45  0.30 -0.33 -0.14  0.06  0.18 -0.06 -0.27 -0.25  0.09  0.12  0.16\n1025-1074   -1  0.02 -0.19 -0.08 -0.08 -0.20 -0.09 -0.18 -0.18  0.19  0.70  0.36 -0.15 -0.01  0.08 -0.13 -0.34 -0.27 -0.14 -0.04  0.11  0.15\n\n# Dataframe is truncated for visualization purposes\n            CAM011      CAM021      CAM031      CAM032      CAM041      CAM042      CAM051      CAM061      CAM062      CAM071      ... CAM151      CAM152  CAM161  CAM162      CAM171      CAM172      CAM181      CAM191      CAM201  CAM211\n700-749     NaN         NaN         NaN         NaN         NaN         NaN         NaN         NaN         NaN         NaN         ... NaN         NaN     NaN     NaN         NaN         NaN         NaN         NaN         NaN     0.402641\n725-774     NaN         NaN         NaN         NaN         NaN         NaN         NaN         NaN         NaN         NaN         ... NaN         NaN     NaN     NaN         NaN         NaN         NaN         NaN         NaN     0.459880\n750-799     NaN         NaN         NaN         NaN         NaN         NaN         NaN         NaN         NaN         NaN         ... NaN         NaN     NaN     NaN         NaN         NaN         NaN         NaN         NaN     0.303433\n1775-1824   0.482449    0.526435    0.294118    0.646002    0.451140    0.489364    0.455558    0.777575    0.862473    0.772677    ... 0.702473    NaN     NaN     0.484946    0.572821    0.578103    0.208547    0.764706    NaN     0.544202\n1800-1849   0.522305    0.456999    0.308715    0.568499    0.581273    0.485234    0.607107    0.790732    0.810612    0.761633    ... 0.782953    NaN     NaN     0.532389    0.523073    0.749052    0.256567    0.810900    NaN     0.568980\n1825-1874   0.545834    0.575606    0.546987    0.625834    0.655030    0.514622    0.572533    0.793421    0.747419    0.652533    ... 0.707275    NaN     NaN     0.494070    0.535942    0.700264    0.411092    0.736471    NaN     0.503770\n1850-1899   0.538631    0.738295    0.656855    0.714382    0.652629    0.655414    0.402929    0.859112    0.801489    0.674430    ... 0.692101    NaN     NaN     0.567827    0.538151    0.672989    0.513661    0.749436    NaN     0.660120\n1875-1924   0.302665    0.751164    0.533637    0.640816    0.461801    0.604994    0.425498    0.709196    0.716879    0.653493    ... 0.689508    NaN     NaN     0.717551    0.542185    0.692869    0.554094    0.679136    NaN     0.683361\n1900-1949   0.153806    0.700456    0.640816    0.696230    0.465738    0.728307    0.385162    0.647155    0.718703    0.493013    ... 0.730612    NaN     NaN     0.628523    0.575222    0.751068    0.423866    0.728307    NaN     0.566963\n1925-1974   0.288836    0.618439    0.560912    0.688547    0.509724    0.637935    0.354238    0.696711    0.813205    0.529220    ... NaN         NaN     NaN     NaN         NaN         NaN         NaN         NaN         NaN     NaN\n</code></pre></p>"},{"location":"manual/#xdate_plot","title":"<code>xdate_plot</code>","text":"<p>Function is under construction</p> <p>Visualize crossdating function in plot form; Each segment correlation is color coded. </p> <p>Usage</p> <pre><code>dpl.xdate_plot(&lt;data&gt;)\n</code></pre> <p>Example: <pre><code># Detrend data first\nca533_rwi = dpl.detrend(ca533, fit=\"spline\", method=\"residual\", plot=False)\n\n# Crossdating of detrended data\ndpl.xdate_plot(ca533_rwi)\n</code></pre></p> <p>Expected output</p> <p>A graph showing segment correlations.</p> <p></p>"}]}